{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is enabled with initial size: 10.0% of memory, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_classes = 43\n",
    "img_size = 32\n",
    "\n",
    "## loading training data\n",
    "import pickle\n",
    "training_set = pickle.load(open(\"/home/aiml_test_user/training_set.pkl\", \"rb\"))\n",
    "\n",
    "## transorforming tha data\n",
    "# resizing all images to one\n",
    "resized_img=[]\n",
    "class_labels = []\n",
    "for i in range(0, len(training_set)):\n",
    "    sample = training_set[i]\n",
    "    image = cv2.resize(sample['img'],(img_size, img_size))\n",
    "    resized_img.append(image)\n",
    "    class_labels.append(sample['class'])\n",
    "    \n",
    "resize_imgs = np.array(resized_img)\n",
    "\n",
    "Y = np.array(class_labels)\n",
    "\n",
    "## dividing by 255\n",
    "X = np.array(resized_img, dtype='float32')\n",
    "X /= 255\n",
    "\n",
    "## swapping axes to input into model\n",
    "X = X.swapaxes(1,3)\n",
    "X.shape\n",
    "\n",
    "\n",
    "## splitting the data into train and test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## model\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(3, img_size, img_size), activation='relu'))\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr*(0.1**int(epoch/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27446 samples, validate on 11763 samples\n",
      "Epoch 1/10\n",
      "27446/27446 [==============================] - 5s - loss: 2.2749 - acc: 0.3529 - val_loss: 0.4749 - val_acc: 0.8464\n",
      "Epoch 2/10\n",
      "27446/27446 [==============================] - 5s - loss: 0.4069 - acc: 0.8706 - val_loss: 0.1085 - val_acc: 0.9691\n",
      "Epoch 3/10\n",
      "27446/27446 [==============================] - 5s - loss: 0.1838 - acc: 0.9424 - val_loss: 0.0694 - val_acc: 0.9794\n",
      "Epoch 4/10\n",
      "27446/27446 [==============================] - 5s - loss: 0.1239 - acc: 0.9623 - val_loss: 0.0394 - val_acc: 0.9894\n",
      "Epoch 5/10\n",
      "27446/27446 [==============================] - 5s - loss: 0.0935 - acc: 0.9714 - val_loss: 0.0394 - val_acc: 0.9889\n",
      "Epoch 6/10\n",
      "27446/27446 [==============================] - 5s - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0318 - val_acc: 0.9915\n",
      "Epoch 7/10\n",
      "27446/27446 [==============================] - 5s - loss: 0.0597 - acc: 0.9825 - val_loss: 0.0328 - val_acc: 0.9912\n",
      "Epoch 8/10\n",
      "27446/27446 [==============================] - 5s - loss: 0.0633 - acc: 0.9809 - val_loss: 0.0504 - val_acc: 0.9863\n",
      "Epoch 9/10\n",
      "27446/27446 [==============================] - 5s - loss: 0.0554 - acc: 0.9835 - val_loss: 0.0319 - val_acc: 0.9917\n",
      "Epoch 10/10\n",
      "27446/27446 [==============================] - 5s - loss: 0.0546 - acc: 0.9833 - val_loss: 0.0243 - val_acc: 0.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f314f6915c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fitting the model\n",
    "batch_size = 30\n",
    "nb_epoch = 10\n",
    "\n",
    "model.fit(x_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(x_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11744/11763 [============================>.] - ETA: 0sTest accuracy: 0.993454050837\n"
     ]
    }
   ],
   "source": [
    "validation = model.evaluate(x_test, Y_test, verbose=1)\n",
    "print('Test accuracy:', validation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_7 (Convolution2D)  (None, 32, 30, 30)    896         convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 32, 28, 28)    9248        convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 32, 14, 14)    0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 32, 14, 14)    0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 64, 14, 14)    18496       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 64, 12, 12)    36928       convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 64, 6, 6)      0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 64, 6, 6)      0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 128, 6, 6)     73856       dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 128, 4, 4)     147584      convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 128, 2, 2)     0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 128, 2, 2)     0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 512)           0           dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 512)           262656      flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 512)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 43)            22059       dropout_8[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 571723\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12630, 3, 32, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## testing\n",
    "import pickle\n",
    "testing_set = pickle.load(open(\"/home/aiml_test_user/testing_set.pkl\", \"rb\"))\n",
    "\n",
    "## preprocessing\n",
    "resized_img_test=[]\n",
    "for i in range(0, len(testing_set)):\n",
    "    sample = testing_set[i]\n",
    "    image = cv2.resize(sample['img'],(img_size, img_size))\n",
    "    resized_img_test.append(image)\n",
    "resize_imgs_test = np.array(resized_img_test)\n",
    "\n",
    "X_test = np.array(resize_imgs_test, dtype='float32')\n",
    "X_test /= 255\n",
    "\n",
    "X_test= X_test.swapaxes(1,3)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12480/12630 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "## predicting the test data\n",
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## saving the predicted data\n",
    "np.savetxt(\"submission.csv\", y_pred, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27446, 3, 32, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## data augmentation\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_val = np_utils.to_categorical(Y_val, nb_classes)\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False, \n",
    "                            featurewise_std_normalization=False, \n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.2,\n",
    "                            shear_range=0.1,\n",
    "                            rotation_range=10.,)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reinstallise models \n",
    "\n",
    "model = cnn_model()\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr*(0.1**int(epoch/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "31367/31367 [==============================] - 13s - loss: 2.8337 - acc: 0.2080 - val_loss: 1.6599 - val_acc: 0.4582\n",
      "Epoch 2/20\n",
      "31367/31367 [==============================] - 11s - loss: 1.3717 - acc: 0.5470 - val_loss: 0.6300 - val_acc: 0.7744\n",
      "Epoch 3/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.6774 - acc: 0.7735 - val_loss: 0.1333 - val_acc: 0.9559\n",
      "Epoch 4/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.3907 - acc: 0.8738 - val_loss: 0.1088 - val_acc: 0.9588\n",
      "Epoch 5/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.2664 - acc: 0.9155 - val_loss: 0.0392 - val_acc: 0.9893\n",
      "Epoch 6/20\n",
      "31367/31367 [==============================] - 11s - loss: 0.2168 - acc: 0.9315 - val_loss: 0.0351 - val_acc: 0.9906\n",
      "Epoch 7/20\n",
      "31367/31367 [==============================] - 13s - loss: 0.1701 - acc: 0.9473 - val_loss: 0.0401 - val_acc: 0.9887\n",
      "Epoch 8/20\n",
      "31367/31367 [==============================] - 15s - loss: 0.1392 - acc: 0.9563 - val_loss: 0.0163 - val_acc: 0.9950\n",
      "Epoch 9/20\n",
      "31367/31367 [==============================] - 15s - loss: 0.1279 - acc: 0.9605 - val_loss: 0.0221 - val_acc: 0.9927\n",
      "Epoch 10/20\n",
      "31367/31367 [==============================] - 13s - loss: 0.1181 - acc: 0.9646 - val_loss: 0.0127 - val_acc: 0.9952\n",
      "Epoch 11/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.1112 - acc: 0.9657 - val_loss: 0.0107 - val_acc: 0.9964\n",
      "Epoch 12/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.0970 - acc: 0.9713 - val_loss: 0.0093 - val_acc: 0.9971\n",
      "Epoch 13/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.0959 - acc: 0.9697 - val_loss: 0.0090 - val_acc: 0.9964\n",
      "Epoch 14/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.0816 - acc: 0.9749 - val_loss: 0.0164 - val_acc: 0.9955\n",
      "Epoch 15/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.0915 - acc: 0.9727 - val_loss: 0.0114 - val_acc: 0.9966\n",
      "Epoch 16/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.0781 - acc: 0.9765 - val_loss: 0.0061 - val_acc: 0.9981\n",
      "Epoch 17/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.0770 - acc: 0.9767 - val_loss: 0.0051 - val_acc: 0.9983\n",
      "Epoch 18/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.0751 - acc: 0.9771 - val_loss: 0.0081 - val_acc: 0.9972\n",
      "Epoch 19/20\n",
      "31367/31367 [==============================] - 11s - loss: 0.0674 - acc: 0.9791 - val_loss: 0.0068 - val_acc: 0.9980\n",
      "Epoch 20/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.0688 - acc: 0.9792 - val_loss: 0.0081 - val_acc: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f98f77842b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 20\n",
    "batch_size = 40\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                            samples_per_epoch=X_train.shape[0],\n",
    "                            nb_epoch=nb_epoch,\n",
    "                            validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12448/12630 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "## predicting the test data\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "## saving the predicted data\n",
    "np.savetxt(\"submission.csv\", y_pred, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "31367/31367 [==============================] - 10s - loss: 2.8136 - acc: 0.2043 - val_loss: 1.6052 - val_acc: 0.4721\n",
      "Epoch 2/20\n",
      "31367/31367 [==============================] - 10s - loss: 1.2541 - acc: 0.5889 - val_loss: 0.3491 - val_acc: 0.8823\n",
      "Epoch 3/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.5423 - acc: 0.8230 - val_loss: 0.1078 - val_acc: 0.9668\n",
      "Epoch 4/20\n",
      "31367/31367 [==============================] - 11s - loss: 0.3212 - acc: 0.8943 - val_loss: 0.0634 - val_acc: 0.9813\n",
      "Epoch 5/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.2366 - acc: 0.9243 - val_loss: 0.0430 - val_acc: 0.9875\n",
      "Epoch 6/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.1841 - acc: 0.9420 - val_loss: 0.0302 - val_acc: 0.9904\n",
      "Epoch 7/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.1612 - acc: 0.9492 - val_loss: 0.0187 - val_acc: 0.9941\n",
      "Epoch 8/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.1367 - acc: 0.9572 - val_loss: 0.0198 - val_acc: 0.9938\n",
      "Epoch 9/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.1287 - acc: 0.9602 - val_loss: 0.0139 - val_acc: 0.9960\n",
      "Epoch 10/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.1161 - acc: 0.9657 - val_loss: 0.0107 - val_acc: 0.9980\n",
      "Epoch 11/20\n",
      "31367/31367 [==============================] - 13s - loss: 0.0971 - acc: 0.9705 - val_loss: 0.0079 - val_acc: 0.9976\n",
      "Epoch 12/20\n",
      "31367/31367 [==============================] - 15s - loss: 0.0957 - acc: 0.9712 - val_loss: 0.0075 - val_acc: 0.9977\n",
      "Epoch 13/20\n",
      "31367/31367 [==============================] - 15s - loss: 0.0877 - acc: 0.9730 - val_loss: 0.0096 - val_acc: 0.9971\n",
      "Epoch 14/20\n",
      "31367/31367 [==============================] - 13s - loss: 0.0771 - acc: 0.9762 - val_loss: 0.0048 - val_acc: 0.9983\n",
      "Epoch 15/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.0844 - acc: 0.9746 - val_loss: 0.0085 - val_acc: 0.9974\n",
      "Epoch 16/20\n",
      "31367/31367 [==============================] - 11s - loss: 0.0743 - acc: 0.9774 - val_loss: 0.0102 - val_acc: 0.9971\n",
      "Epoch 17/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.0802 - acc: 0.9750 - val_loss: 0.0061 - val_acc: 0.9978\n",
      "Epoch 18/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.0653 - acc: 0.9804 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Epoch 19/20\n",
      "31367/31367 [==============================] - 10s - loss: 0.0673 - acc: 0.9794 - val_loss: 0.0028 - val_acc: 0.9991\n",
      "Epoch 20/20\n",
      "31367/31367 [==============================] - 11s - loss: 0.0580 - acc: 0.9830 - val_loss: 0.0046 - val_acc: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f98f43189b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## data augmentation - part 2\n",
    "X_train, X_val, Y_train,Y_val = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_val = np_utils.to_categorical(Y_val, nb_classes)\n",
    "\n",
    "datagen1 = ImageDataGenerator(featurewise_center=True,\n",
    "                             featurewise_std_normalization=True,\n",
    "                             rotation_range=20,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             horizontal_flip=True)\n",
    "\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "datagen1.fit(X_train)\n",
    "\n",
    "# Reinstallise models \n",
    "\n",
    "model = cnn_model()\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr*(0.1**int(epoch/10))\n",
    "\n",
    "\n",
    "nb_epoch = 20\n",
    "batch_size = 40\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                            samples_per_epoch=X_train.shape[0],\n",
    "                            nb_epoch=nb_epoch,\n",
    "                            validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## predicting the test data\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "## saving the predicted data\n",
    "np.savetxt(\"submission.csv\", y_pred, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
